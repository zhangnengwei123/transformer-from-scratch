{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e83a30bc-21f5-45c0-ad48-d7e849b23d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17ae6329-ceb7-4e0f-86e0-2983c0348033",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentences = [\n",
    "    # enc_input           dec_input         dec_output\n",
    "    ['ich mochte ein bier P', 'S i want a beer .', 'i want a beer . E'],\n",
    "    ['ich mochte ein cola P', 'S i want a coke .', 'i want a coke . E']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aec51130-702c-415d-9dc9-d51909dd05bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ich mochte ein bier P', 'S i want a beer .', 'i want a beer . E'],\n",
       " ['ich mochte ein cola P', 'S i want a coke .', 'i want a coke . E']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55d17aee-a1f5-46dc-85cd-adaaa2ac40a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Padding Should be Zero\n",
    "source_vocab = {'P': 0, 'ich': 1, 'mochte': 2, 'ein': 3, 'bier': 4, 'cola': 5}\n",
    "source_vocab_size = len(source_vocab)\n",
    "\n",
    "target_vocab = {'P': 0, 'i': 1, 'want': 2, 'a': 3, 'beer': 4, 'coke': 5, 'S': 6, 'E': 7, '.': 8}\n",
    "idx2word = {i: w for i, w in enumerate(target_vocab)}\n",
    "target_vocab_size = len(target_vocab)\n",
    "source_len = 5  # max length of input sequence\n",
    "target_len = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "001421cd-a3c4-4bf5-96f3-37ecb81fafc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_data(sentences):\n",
    "    encoder_inputs, decoder_inputs, decoder_outputs = [], [], []\n",
    "    for i in range(len(sentences)):\n",
    "        encoder_input = [source_vocab[word] for word in sentences[i][0].split()]\n",
    "        decoder_input = [target_vocab[word] for word in sentences[i][1].split()]\n",
    "        decoder_output = [target_vocab[word] for word in sentences[i][2].split()]\n",
    "        encoder_inputs.append(encoder_input)\n",
    "        decoder_inputs.append(decoder_input)\n",
    "        decoder_outputs.append(decoder_output)\n",
    "\n",
    "    return torch.LongTensor(encoder_inputs), torch.LongTensor(decoder_inputs), torch.LongTensor(decoder_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec504a37-a278-46a4-b4f5-201e34b248ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data as Data\n",
    "class Seq2SeqDataset(Data.Dataset):\n",
    "\n",
    "    def __init__(self, encoder_input, decoder_input, decoder_output):\n",
    "        super(Seq2SeqDataset, self).__init__()\n",
    "        self.encoder_input = encoder_input\n",
    "        self.decoder_input = decoder_input\n",
    "        self.decoder_output = decoder_output\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.encoder_input.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.encoder_input[idx], self.decoder_input[idx], self.decoder_output[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56bf242f-7244-4fe0-9684-80eb122d3c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs, decoder_inputs, decoder_outputs = make_data(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5f3c184-658f-4eca-abc2-7f985092ac9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4, 0],\n",
       "        [1, 2, 3, 5, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d251145a-12d5-4f34-b735-8e38da54f165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6, 1, 2, 3, 4, 8],\n",
       "        [6, 1, 2, 3, 5, 8]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5c9986f-b96e-4ee4-99bc-1bafada0090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_pad_mask(t, pad):\n",
    "    r\"\"\"\n",
    "    在Encoder中使用Mask, 是为了将Encoder_inputs中没有内容而打上PAD的部分进行Mask, 方便矩阵运算.\n",
    "    在Decoder中使用Mask, 可能是在Decoder的自注意力对Decoder_inputs的PAD进行Mask,\n",
    "    也有可能是对Encoder-outputs的PAD进行Mask.\n",
    "\n",
    "    :param t: [batch_size, seq_len]\n",
    "    :param pad:\n",
    "    :return: [batch_size, 1, seq_len]\n",
    "    \"\"\"\n",
    "    mask = t.data.eq(pad).unsqueeze(1)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e06daee-2d4a-4215-91ff-8d6a5eba4a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_target_self_mask(target_len):\n",
    "    r\"\"\"\n",
    "    生成上三角的矩阵\n",
    "\n",
    "    在Decoder中使用Mask, 在Decoder的自注意力对Decoder_inputs进行Mask,\n",
    "    :param target_len:\n",
    "    :return:[batch, target_len, target_len]\n",
    "    \"\"\"\n",
    "    ones = torch.ones(target_len, target_len, dtype=torch.uint8)\n",
    "    self_mask = torch.triu(ones, diagonal=1).unsqueeze(0)\n",
    "    return self_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "67cb2e72-f344-4d3a-9cb0-4e2506b216c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_mask = create_pad_mask(encoder_inputs, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88170b22-05c6-4c0b-898b-4edde00e772d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[False, False, False, False,  True]],\n",
       "\n",
       "        [[False, False, False, False,  True]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2bb3de5-340d-41f6-b740-da06ec74abaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_feedforward = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac22f53a-18a1-4669-93e0-8d767c6286a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_feedforward ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed0b35c-3212-44f2-be1b-f3f2038969a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
