{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3e6b2257-88f5-42ba-a0ec-fd61d581fef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "# Block Size（块大小）是指在处理文本时，模型一次读取或生成的最大文本长度。\n",
    "block_size = 8\n",
    "# Batch Size（批大小）是指在一次训练迭代中，模型同时处理的样本数。\n",
    "batch_size = 4\n",
    "\n",
    "learning_rate = 1e-3\n",
    "max_iters = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b07a1e2f-6889-4d71-b568-feb83b4b1b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378436\n",
      "The Project Gutenberg eBook of Hollyhock House: A Story for Girls\n",
      "\n",
      "This ebook is for the use of anyone anywhere in the United States and\n",
      "most other parts of the world at no cost and with almost no res\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('ebook_free.text', 'r', encoding='UTF-8') as f:\n",
    "    text = f.read()\n",
    "print(len(text))\n",
    "print(text[:200])  # 打印前200个字符\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45a6a2d3-7211-45d0-bbba-53e4c7e950eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "['\\n', ' ', '!', '#', '$', '%', '&', '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'è', 'é', 'ê', 'ï', 'ô', 'ö', 'ü', '—', '‘', '’', '“', '”', '•', '™']\n"
     ]
    }
   ],
   "source": [
    "# 将每个字符找出来，做成词汇表\n",
    "chars = sorted(set(text))\n",
    "print(len(chars))\n",
    "print(chars)\n",
    "vocabulary_size = len(chars)  # 词汇表大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1639b860-64a6-43dd-9cd5-d240ceb54e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63, 60, 67, 67, 70]\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 制作编码器解码器\n",
    "# for i, ch in enumerate(chars):\n",
    "#     print(f\"{i}:{ch}\")\n",
    "\n",
    "string_to_int = {ch: i for i, ch in enumerate(chars)}\n",
    "int_to_string = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: \"\".join([int_to_string[i] for i in l])\n",
    "\n",
    "print(encode(\"hello\"))\n",
    "print(decode([63, 60, 67, 67, 70]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eb2386c-5a31-4273-b6a4-83fb3ab57f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([46, 63, 60,  1, 42, 73, 70, 65, 60, 58, 75,  1, 33, 76, 75, 60, 69, 57,\n",
      "        60, 73, 62,  1, 60, 28, 70, 70, 66,  1, 70, 61,  1, 34, 70, 67, 67, 80,\n",
      "        63, 70, 58, 66,  1, 34, 70, 76, 74, 60, 24,  1, 27,  1, 45, 75, 70, 73,\n",
      "        80,  1, 61, 70, 73,  1, 33, 64, 73, 67, 74,  0,  0, 46, 63, 64, 74,  1,\n",
      "        60, 57, 70, 70, 66,  1, 64, 74,  1, 61, 70, 73,  1, 75, 63, 60,  1, 76,\n",
      "        74, 60,  1, 70, 61,  1, 56, 69, 80, 70])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 使用torch处理数据\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data[:100])\n",
    "\n",
    "# 分成训练集 验证集\n",
    "n = int(0.8 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7ab5afe-fb0d-431a-805d-df8e90a2b032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([46, 63, 60,  1, 42, 73, 70, 65, 60, 58, 75,  1, 33, 76, 75, 60, 69, 57,\n",
      "        60, 73, 62,  1, 60, 28, 70, 70, 66,  1, 70, 61,  1, 34, 70, 67, 67, 80,\n",
      "        63, 70, 58, 66,  1, 34, 70, 76, 74, 60, 24,  1, 27,  1, 45, 75, 70, 73,\n",
      "        80,  1, 61, 70, 73,  1, 33, 64, 73, 67, 74,  0,  0, 46, 63, 64, 74,  1,\n",
      "        60, 57, 70, 70, 66,  1, 64, 74,  1, 61, 70, 73,  1, 75, 63, 60,  1, 76,\n",
      "        74, 60,  1, 70, 61,  1, 56, 69, 80, 70])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 使用torch处理数据\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data[:100])\n",
    "\n",
    "# 分成训练集 验证集\n",
    "n = int(0.8 * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "61b4035a-f839-401b-81a7-077c5ed670d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([46]) target is tensor(63)\n",
      "when input is tensor([46, 63]) target is tensor(60)\n",
      "when input is tensor([46, 63, 60]) target is tensor(1)\n",
      "when input is tensor([46, 63, 60,  1]) target is tensor(42)\n",
      "when input is tensor([46, 63, 60,  1, 42]) target is tensor(73)\n",
      "when input is tensor([46, 63, 60,  1, 42, 73]) target is tensor(70)\n",
      "when input is tensor([46, 63, 60,  1, 42, 73, 70]) target is tensor(65)\n",
      "when input is tensor([46, 63, 60,  1, 42, 73, 70, 65]) target is tensor(60)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 通过现在的输入x预测y，看看怎么回事吧\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size + 1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t + 1]\n",
    "    target = y[t]\n",
    "    print(\"when input is\", context, \"target is\", target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "11094182-1c90-4523-98a8-3fbf54cbb359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "tensor([[59, 24,  1, 92, 34, 60, 73,  1],\n",
      "        [80, 70, 76,  1, 67, 60, 56, 73],\n",
      "        [73, 59, 60, 69,  0, 61, 73, 70],\n",
      "        [ 1,  1,  1,  1,  1, 32, 27, 29]])\n",
      "targets:\n",
      "tensor([[24,  1, 92, 34, 60, 73,  1, 57],\n",
      "        [70, 76,  1, 67, 60, 56, 73, 69],\n",
      "        [59, 60, 69,  0, 61, 73, 70, 68],\n",
      "        [ 1,  1,  1,  1, 32, 27, 29, 35]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 引入batch size进行并行处理 提升性能\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    # 生成batch_size个随机数\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i + block_size] for i in ix])\n",
    "    y = torch.stack([data[i + 1:i + block_size + 1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "\n",
    "x, y = get_batch('train')\n",
    "print('inputs:')\n",
    "print(x)\n",
    "print('targets:')\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "57685cdd-3a1c-4663-91bd-b6ed82dc281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建embedding表\n",
    "token_embedding_table = nn.Embedding(vocabulary_size, vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "470b5b2d-e33b-421e-a9c0-0cff602c3417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取input\n",
    "input_logits = token_embedding_table(x)\n",
    "N1, N2, C = input_logits.shape\n",
    "# [4,8,96]\n",
    "# [batch_size,block_size,vocabulary_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d9e2922f-b955-494c-9a43-73675d9efaac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "72f5a239-77ad-450d-8ef1-3c642e5b4683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备交叉熵函数的输入\n",
    "input_logits = input_logits.view(N1 * N2, C)\n",
    "targets = y.view(N1 * N2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c32b63e9-74f1-47d2-a317-cd54714cbf80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 96])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ca08cf04-2741-40c0-9322-63184e41a268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "09c421cc-15c3-47d7-9da1-a6edbba39039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算loss\n",
    "# 交叉熵函数 input(N,C) targets(N)\n",
    "loss = F.cross_entropy(input_logits, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1351ea5a-11e7-43cb-877e-f962c9f7e888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.3405, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "768f25e5-670d-4926-b3b8-43153cec4828",
   "metadata": {},
   "outputs": [],
   "source": [
    "gx = token_embedding_table(x)[:, -1, :]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "72fa41fc-38eb-4ab0-9dd6-33914190a910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 96])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a5ea3c26-2888-4e1b-a4a8-0ea37384428e",
   "metadata": {},
   "outputs": [],
   "source": [
    " probs = F.softmax(gx, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1af6588e-a9d2-4ca3-9684-298af0696b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 96])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5c50e5f5-8eeb-4703-b836-392caf36c8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_next = torch.multinomial(probs, num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3698b38e-ea50-4b5d-82d2-2349ae816974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20],\n",
       "        [22],\n",
       "        [77],\n",
       "        [42]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bd55e70e-ce4b-4ebd-a97d-2a42d59985e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[56, 59,  1, 56, 62, 56, 64, 69],\n",
       "        [ 1, 57, 60, 60, 69,  1, 61, 70],\n",
       "        [57, 73, 60, 56, 75, 63, 67, 60],\n",
       "        [74, 75, 80,  1, 56, 74,  1, 56]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8a7514d7-72e4-4ac3-bbc1-027cad8d3ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocabulary_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocabulary_size, vocabulary_size)\n",
    "\n",
    "    # 前向传播\n",
    "    def forward(self, input_index, targets):\n",
    "        input_logits = self.token_embedding_table(input_index)\n",
    "        N1, N2, C = input_logits.shape\n",
    "        N = N1*N2\n",
    "        input = input_logits.view(N, C)\n",
    "        targets = targets.view(N)\n",
    "        # 交叉熵函数 input(N,C) targets(N)\n",
    "        loss = F.cross_entropy(input, targets)\n",
    "        return input, loss\n",
    "\n",
    "    # 获取logits\n",
    "    def get_logits(self,input_index):\n",
    "        return self.token_embedding_table(input_index)\n",
    "\n",
    "    # 生成预测文本\n",
    "    def generate(self, input_index, max_new_tokens):\n",
    "        # input_index是当前上下文（B,T）数组的下标\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits = self.get_logits(input_index)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :]  # becomes (B,C)\n",
    "            probs = F.softmax(logits, dim=-1)  # (B,C)\n",
    "            index_next = torch.multinomial(probs, num_samples=1)\n",
    "            input_index = torch.cat((input_index, index_next), dim=1)  # (B,T+1)\n",
    "        return input_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "24d384d2-280e-4f84-905d-9e83d667d759",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BigramLanguageModel(vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b9f3f8b2-6077-4695-9617-a04c781c2540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.2128,  1.3049, -0.5040,  ..., -0.6487, -1.5353, -0.2212],\n",
       "         [ 0.6039,  1.5666,  0.4391,  ...,  0.0611,  1.7136, -1.9198],\n",
       "         [ 0.3596,  1.1008, -1.3913,  ..., -0.9286,  2.2723, -0.2173],\n",
       "         ...,\n",
       "         [-0.1482, -0.1238,  0.4463,  ...,  1.4030, -0.1056, -1.5375],\n",
       "         [ 0.3596,  1.1008, -1.3913,  ..., -0.9286,  2.2723, -0.2173],\n",
       "         [ 0.2128,  1.3049, -0.5040,  ..., -0.6487, -1.5353, -0.2212]],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " tensor(4.7015, grad_fn=<NllLossBackward0>))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4c74502a-e65e-45e6-a067-7f89152585ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NjEs”3VDSd,üOMS][LVL%RdiiR 5A/on“s8\n",
      "“a)’\n",
      "GZ31b,ê,0\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "generated_chars = decode(model.generate(context, max_new_tokens=50)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8af2b6de-526b-4e2a-8ac9-14d8cb9edb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "55d05feb-e840-4fa9-9070-4d9955629790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:0,loss:{'train': tensor(4.7751), 'val': tensor(4.8006)}\n",
      "step:100,loss:{'train': tensor(4.7352), 'val': tensor(4.7502)}\n",
      "step:200,loss:{'train': tensor(4.6144), 'val': tensor(4.6214)}\n",
      "step:300,loss:{'train': tensor(4.5553), 'val': tensor(4.6049)}\n",
      "step:400,loss:{'train': tensor(4.4575), 'val': tensor(4.4807)}\n",
      "step:500,loss:{'train': tensor(4.3733), 'val': tensor(4.4423)}\n",
      "step:600,loss:{'train': tensor(4.3279), 'val': tensor(4.3370)}\n",
      "step:700,loss:{'train': tensor(4.2131), 'val': tensor(4.2547)}\n",
      "step:800,loss:{'train': tensor(4.2079), 'val': tensor(4.2177)}\n",
      "step:900,loss:{'train': tensor(4.1163), 'val': tensor(4.1478)}\n"
     ]
    }
   ],
   "source": [
    "max_iters=1000\n",
    "eval_iters = 100\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    if iter % eval_iters == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step:{iter},loss:{losses}\")\n",
    "\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = model.forward(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752fe1a5-3929-48ce-a069-c7e1682915bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
